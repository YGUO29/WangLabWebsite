<!DOCTYPE HTML>
<!--
	Helios by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Wang Lab - research</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<!--[if lte IE 8]><script src="assets/js/ie/html5shiv.js"></script><![endif]-->
		<link rel="stylesheet" href="assets/css/main.css" />
		<!--[if lte IE 8]><link rel="stylesheet" href="assets/css/ie8.css" /><![endif]-->
        <base target="_blank">
	</head>
	<body class="right-sidebar">
		<div id="page-wrapper">

			<!-- Header -->
				<div id="header">
					<!-- Inner -->
						<div class="inner">
							<header>
								<h1><a href="index.html" id="logo"> Research Highlights - Vocalization</a></h1>
							</header>
						</div>

<!-- shared navigation starts here -->                    
                    <nav id="nav">
                    <ul>
                    <li><a href="index.html" target="_self">Home</a></li>

                    <!--research headlin-->
                    <li>
                        <a href="#">Research</a>
                        <ul>

                            <li><a href="1review.html" target="_self"> Review Articles </a></li>
                            <li><a href="2coding.html" target="_self"> Neural Coding </a></li>
                            <li><a href="3vocalization.html" target="_self"> Vocalization </a></li>
                            <li><a href="4pitch.html" target="_self"> Pitch and Harmonics </a></li>
                            <li><a href="5localization.html" target="_self"> Sound Localization </a></li>
                            <li><a href="6ci.html" target="_self"> Cochlear Implant</a></li>
                            <li><a href="7behav.html" target="_self"> Behavior and Psychophysics </a></li>
                            <li><a href="8method.html" target="_self"> Methods </a></li>
                        </ul>
                    </li>

                    <!--people headline (left-sidebar)-->
                    <li><a href="people.html" target="_self">People</a></li>
                    <!--publication headline (right-sidebar-->
                    <li><a href="publication.html" target="_self"> Publications </a></li>
                    <!--photos headline (no sidebar)-->
                    <li><a href="adventure.html" target="_self">Adventures</a></li>
                    <li><a href="positions.html" target="_self">Positions</a></li>
                    </ul>
                    </nav>
<!-- shared navigation ends here -->    
				</div>

			<!-- Main -->
				<div class="wrapper style1">
					<div class="container">
						<div class="row 200%">
							
                            <div class="8u 12u(mobile)" id="content" >
								<article id="main" >
                                   
                                <section><h3><i>We record vocalizations of marmosets in the colony, quantitatively characterize their vocalization repertoires and correlate vocalizations with their behaviors, to understand how marmoset vocalizations play an important role in their social interactions; Using wireless recording arrays implanted in the auditory cortex and prefontal cortex, we are able to record neural activities in the freely-roaming condition in order to study the neural mechanisms underlying vocal production, perception, and auditory-vocal interactions. </i></h3></section>    
<!--2017, Eliades,  --> 
                                <section>
                                <h3><a href="http://www.sciencedirect.com/science/article/pii/S037859551630586X?via%3Dihub">Contributions of sensory tuning to auditory-vocal interactions in marmoset auditory cortex</a></h3>
                                </section>
                                <section>
                                <a href="http://ars.els-cdn.com/content/image/1-s2.0-S037859551630586X-gr2.jpg" class="image research-left"><img src="images/research/3-6.jpg" alt="" /></a>
                                <p><b>(Eliads and Wang, 2017) </b> Previous studies in naturally vocalizing marmosets have demonstrated diverse neural activities in auditory cortex during vocalization, dominated by a vocalization-induced suppression of neural firing. How underlying auditory tuning properties of these neurons might contribute to this sensory-motor processing is unknown. In the present study, we quantitatively compared marmoset auditory cortex neural activities during vocal production with those during passive listening. We found that neurons excited during vocalization were readily driven by passive playback of vocalizations and other acoustic stimuli. In contrast, neurons suppressed during vocalization exhibited more diverse playback responses, including responses that were not predictable by auditory tuning properties. These results suggest that vocalization-related excitation in auditory cortex is largely a sensory-driven response. In contrast, vocalization-induced suppression is not well predicted by a neuron's auditory responses, supporting the prevailing theory that internal motor-related signals contribute to the auditory-vocal interaction observed in auditory cortex. </p>    
                                <p style="font-size: 14px">
                                Fig. 2. Sample units suppressed during vocalization, but with different playback responses. One unit (A-D) was suppressed during trillphee vocal production as well as during playback (though with some delay). The second unit (E-H) was suppressed during trill production, but strongly driven during playback. The second type of unit was more commonly encountered than the first.
                                
                                </p>
                                </section>      
<!--2016, Roy,  --> 
                                <section>
                                <h3><a href="http://scitation.aip.org/content/asa/journal/jasa/138/5/10.1121/1.4934268">Distinct Neural Activities in Premotor Cortex during Natural Vocal Behaviors in a New World Primate, the Common Marmoset (Callithrix jacchus)</a></h3>
                                </section>
                                <section>
                                <a href="http://www.jneurosci.org/content/jneuro/36/48/12168/F5.large.jpg" class="image research-right"><img src="images/research/3-5.jpg" alt="" /></a>
                                <p><b>(Roy et al., 2016) </b> Using a wireless multichannel neural recording technique, we observed in the premotor cortex neural activation and suppression both before and during self-initiated vocalizations when marmosets, a highly vocal New World primate species, engaged in vocal exchanges with conspecifics. A novel finding of the present study is the discovery of a subpopulation of premotor cortex neurons that was activated by vocal production, but not by orofacial movement. These observations provide clear evidence of the premotor cortex's involvement in vocal production in a New World primate species.</p>    
                                <p style="font-size: 14px">
                                Figure 2. Population-averaged normalized firing rates (z-score, mean ± SEM) of the vocal-only neurons in each of the three experimental conditions. A, B, Vocal production. C, D, Orofacial movement (licking). E, F, Playback. The vocal-only neurons are separated into two groups, activated (A, C, E) and suppressed (B, D, F) in the vocal production condition. The shaded bars indicate the average durations of each phee call phrase (A, B, E, F) or averaged duration of the licking (C, D).
                                
                                </p>
                                </section>                                    
<!--2015, Agamite,  -->
                                <section>
                                <h3><a href="http://scitation.aip.org/content/asa/journal/jasa/138/5/10.1121/1.4934268">A quantitative acoustic analysis of the vocal repertoire of the common marmoset</a></h3>
                                </section>
                                <section>
                                <a href="http://scitation.aip.org/content/figure/asa/journal/jasa/138/5/10.1121/1.4934268.f2" class="image research-left"><img src="images/research/3-1.gif" alt="" /></a>
                                <p><b>(Agamite et al., 2015) </b> Previous classifications of the marmoset vocal repertoire were mostly based on qualitative observations. In the present study a variety of vocalizations from individually identified marmosets were sampled and multiple acoustic features of each type of vocalization were measured. Results show that marmosets have a complex vocal repertoire in captivity that consists of multiple vocalization types, including both simple calls and compound calls composed of sequences of simple calls. A detailed quantification of the vocal repertoire of the marmoset can serve as a solid basis for studying the behavioral significance of their vocalizations and is essential for carrying out studies that investigate such properties as perceptual boundaries between call types and among individual callers as well as neural coding mechanisms for vocalizations. It can also serve as the basis for evaluating abnormal vocal behaviors resulting from diseases or genetic manipulations.</p>    
                                <p style="font-size: 14px">
                               Figure 2. Signal representations used to measure the acoustic features. (A) Time waveform (gray) and envelope (black) of a twitter call, with detected envelope peaks marked with “+” symbols. (B) Smoothed magnitude of the frequency spectrum for the beginning phrase of a twitter call. The “*” symbol marks the detected spectral peak. (C) Spectrogram and time-frequency trace for the beginning phrase of a twitter call. The minimum and maximum detected frequencies are shown along with the sweep time. (D) Spectrogram and time-frequency trace for a trillphee call. The + markers indicate detected peaks in the FM sinusoid segment of the call, the “O” markers indicate detected troughs in the FM sinusoid segment of the call, and the O marker indicates where the transition point from the FM sinusoidal to tonal segment of the call was detected. The markers in all signal representations were generated using automated feature detection software.
                                </p>
                                </section>
                            
<!--2013, Sabyasachi, noise interference -->
                            <section>
                            <h3><a href="http://jeb.biologists.org/content/214/21/3619">Vocal control by the common marmoset in the presence of interfering noise</a></h3>
                            </section>
                            <section>
                                <a href="http://d3e3jwjal5zk9x.cloudfront.net/content/jexbio/214/21/3619/F1.large.jpg" class="image research-right"><img src="images/research/3-2.jpg" alt="" /></a>
                                <p><b>(Sabyasachi et al., 2011)</b> The natural environment is inherently noisy with acoustic interferences. It is, therefore, beneficial for a species to modify its vocal production to effectively communicate in the presence of interfering noises. Non-human primates have been traditionally considered to possess limited voluntary vocal control, but little is known about their ability to modify vocal behavior when encountering interfering noises. Here we tested the ability of the common marmoset (Callithrix jacchus) to control the initiation of vocalizations and maintain vocal interactions between pairs in an acoustic environment in which the length and predictability (periodic or random aperiodic occurrences) of interfering noise bursts were varied. Despite the presence of interfering noise, the marmosets continued to engage in antiphonal calling behavior. Results showed that the overwhelming majority of calls were initiated during silence gaps even when the length of the silence gap following each noise burst was unpredictable. During the periodic noise conditions, as the length of the silence gap decreased, the latency between the end of noise burst and call onset decreased significantly. In contrast, when presented with aperiodic noise bursts, the marmosets chose to call predominantly during long (4 and 8 s) over short (2 s) silence gaps. In the 8 s periodic noise conditions, a marmoset pair either initiated both calls of an antiphonal exchange within the same silence gap or exchanged calls in two consecutive silence gaps. Our findings provide compelling evidence that common marmosets are capable of modifying their vocal production according to the dynamics of their acoustic environment during vocal communication.</p>
                                <p style="font-size: 14px">
                                Figure 1. Acoustic recordings of marmoset phee calls made during different noise conditions: (A) periodic: 4 s, (B) aperiodic: predictable, (C) aperiodic: unpredictable. The latency between noise offset and call onset is indicated in B. (D) Left: amplitude of a three-phrase phee call recorded during a baseline session (top), overlapped with noise (middle) and de-noised (bottom). The average power of the phee call was 30 dB SPL. Right: spectrograms of the waveforms shown to the left. After de-noising, the soft phee call is clearly detectable.
									</p>
                                    </section>

<!--2008, Eliades -->                         
                            <section>
                            <h3><a href="http://www.nature.com/nature/journal/v453/n7198/abs/nature06910.html">Neural substrates of vocalization feedback monitoring in primate auditory cortex</a></h3>
                            <p style="font-size: 14px"></p>
                            </section>
                                    
                            <section>
                            <a href="http://www.nature.com/nature/journal/v436/n7054/fig_tab/nature03867_F1.html" class="image research-left"><img src="images/research/3-3.jpg" alt="" /></a>
                            <p><b>(Eliades and Wang, 2008)</b> Vocal communication involves both speaking and hearing, often taking place concurrently. Vocal production, including human speech and animal vocalization, poses a number of unique challenges for the auditory system. It is important for the auditory system to monitor external sounds continuously from the acoustic environment during speaking despite the potential for sensory masking by self-generated sounds1. It is also essential for the auditory system to monitor feedback of one's own voice. This self-monitoring may play a part in distinguishing between self-generated or externally generated auditory inputs and in detecting errors in our vocal production. Previous work in humansand other animals has demonstrated that the auditory cortex is largely suppressed during speaking or vocalizing. Despite the importance of self-monitoring, the underlying neural mechanisms in the mammalian brain, in particular the role of vocalization-induced suppression, remain virtually unknown. Here we show that neurons in the auditory cortex of marmoset monkeys (Callithrix jacchus) are sensitive to auditory feedback during vocal production, and that changes in the feedback alter the coding properties of these neurons. Furthermore, we found that the previously described cortical suppression during vocalization actually increased the sensitivity of these neurons to vocal feedback. This heightened sensitivity to vocal feedback suggests that these neurons may have an important role in auditory self-monitoring.</p>
                            <p style="font-size: 14px">
                            Figure 1: Examples of vocal suppression and excitation during altered feedback. a, Spectrogram of a marmoset phee vocalization. b, Raster plot of action potentials before, during and after phees recorded from an auditory cortex neuron that was suppressed during normal vocal production. Shaded areas indicate duration of phees. Neural responses are shown during normal, baseline vocalizations (blue), +2 semitone frequency-shifted feedback (red), and amplified but unshifted feedback (black). Multiple vocalizations and corresponding cortical responses were recorded in each condition. c, Peri-stimulus time histogram (PSTH) illustrating the large increase in firing rate compared to baseline (blue) during frequency-shifted (red), but not amplified (black), feedback. d, Spectrogram of a sample trill vocalization. e, f, Raster plot (e) and PSTH (f) of an excited neuron whose firing also increased during a +2 semi-tone frequency shift, but not during feedback amplification.
                            </p>
                            </section> 
                                    
<!--2003, Eliades -->                         
                            <section>
                            <h3><a href="http://jn.physiology.org/content/89/4/2194.short">Sensory-Motor Interaction in the Primate Auditory Cortex During Self-Initiated Vocalizations</a></h3>
                            <p style="font-size: 14px"></p>
                            </section>
                                    
                            <section>
                            <a href="http://jn.physiology.org/content/jn/89/4/2194/F2.large.jpg" class="image research-right"><img src="images/research/3-4.jpg" alt="" /></a>
                            <p><b>(Eliades and Wang, 2003)</b> The present study investigated single-unit activities in the auditory cortex of a vocal primate, the common marmoset (Callithrix jacchus), during self-initiated vocalizations. We found that1) self-initiated vocalizations resulted in suppression of neural discharges in a majority of auditory cortical neurons. The vocalization-induced inhibition suppressed both spontaneous and stimulus-driven discharges. Suppressed units responded poorly to external acoustic stimuli during vocalization. 2) Vocalization-induced suppression began several hundred milliseconds prior to the onset of vocalization. 3) The suppression of cortical discharges reduced neural firings to below the rates expected from a unit's rate-level function, adjusted for known subcortical attenuation, and therefore was likely not entirely caused by subcortical attenuation mechanisms. 4) A smaller population of auditory cortical neurons showed increased discharges during self-initiated vocalizations. This vocalization-related excitation began after the onset of vocalization and is likely the result of acoustic feedback. Units showing this excitation responded nearly normally to external stimuli during vocalization. Based on these findings, we propose that the suppression of auditory cortical neurons, possibly originating from cortical vocal production centers, acts to increase the dynamic range of cortical responses to vocalization feedback for self monitoring. The excitatory responses, on the other hand, likely play a role in maintaining hearing sensitivity to the external acoustic environment during vocalization.</p>
                            <p style="font-size: 14px">
                            Figure 2: A: an example in which a self-initiated vocalization completely suppresses stimulus-driven discharges. The presence of external acoustic stimuli (playback of vocalizations presented at 70 dB) is indicated by bars above the neural recording trace.B: a peristimulus time histogram (PSTH,top) is shown for the same unit as in Ain response to passive playback of a previously recorded vocalization (bottom). The dashed line indicates the mean spontaneous firing rate and the green bar (top) specifies the duration of statistically significant response (P < 0.05, see methods). Although the self-produced vocalization (A) was spectrally similar to the playback vocalization (B), both with similar intensities (80 dB), they had opposite effects on the discharges of the unit shown.
                            </p>
                            </section>
                                    
                            </article>
                            </div>

							<div class="4u 12u(mobile)" id="sidebar">
                            <hr class="first" />
                            <section>
<!--  related publication -->                             
                            <header>
                            <h3>Related publications</h3>
                            </header>
                                <ul>
                                    <li type="square">Eliades, Steven J., and Xiaoqin Wang. "Contributions of sensory tuning to auditory-vocal interactions in marmoset auditory cortex." Hearing Research (2017).
                                        <a href="http://www.sciencedirect.com/science/article/pii/S037859551630586X?via%3Dihub">[web]</a>
                                        <a href="publications/2017_HearingRes_Eliades.pdf"> [pdf]</a>
                                    </li>
                                    
                                    <li type="square">Roy, Sabyasachi, Lingyun Zhao, and Xiaoqin Wang. "Distinct Neural Activities in Premotor Cortex during Natural Vocal Behaviors in a New World Primate, the Common Marmoset (Callithrix jacchus)" Journal of Neuroscience (2016).
                                    <a href="http://www.jneurosci.org/content/36/48/12168">[web]</a>
                                        <a href="publications/2016_JNeurosci_Lingyun.pdf"> [pdf]</a>
                                    </li>
                                    
                                    <li type="square">Agamaite, James A., Chia-Jung Chang, Michael S. Osmanski, and Xiaoqin Wang. "A quantitative acoustic analysis of the vocal repertoire of the common marmoset (Callithrix jacchus)." The Journal of the Acoustical Society of America 138, no. 5 (2015): 2906-2928.
                                    <a href="http://scitation.aip.org/content/asa/journal/jasa/138/5/10.1121/1.4934268">[web]</a>
                                        <a href="publications/2015_JASA_Agamaite_vocalization.pdf"> [pdf]</a>
                                    </li>
                                    <li type="square">Eliades, Steven J., and Xiaoqin Wang. "Comparison of auditory-vocal interactions across multiple types of vocalizations in marmoset auditory cortex." Journal of neurophysiology 109, no. 6 (2013): 1638-1657.
                                    <a href="http://jn.physiology.org/content/109/6/1638.short">[web]</a>
                                        <a href="publications/2013_JNeurophysiol_Eliades_vocalization.pdf"> [pdf]</a>
                                    </li>
                                    <li type="square">Eliades, Steven J., and Xiaoqin Wang. "Neural correlates of the Lombard effect in primate auditory cortex." The Journal of Neuroscience 32, no. 31 (2012): 10737-10748.
                                    <a href="https://www.jneurosci.org/content/32/31/10737.full">[web]</a>
                                        <a href="publications/2012_JNeurosci_Eliades_lombard.pdf"> [pdf]</a>
                                    </li>
                                    <li type="square">Roy, Sabyasachi, and Xiaoqin Wang. "Wireless multi-channel single unit recording in freely moving and vocalizing primates." Journal of neuroscience methods 203, no. 1 (2012): 28-40.
                                    <a href="http://www.sciencedirect.com/science/article/pii/S0165027011005267">[web]</a>
                                        <a href="publications/2012_JNeurosciMethods_Roy.pdf"> [pdf]</a>
                                    </li>
                                    <li type="square">Roy, Sabyasachi, Cory T. Miller, Dane Gottsch, and Xiaoqin Wang. "Vocal control by the common marmoset in the presence of interfering noise." The Journal of experimental biology 214, no. 21 (2011): 3619-3629.
                                    <a href="http://jeb.biologists.org/content/214/21/3619.short">[web]</a>
                                        <a href="publications/2011_JExpBio_Roy.pdf"> [pdf]</a>
                                    </li>
                                    
                                    <li type="square">Miller, Cory T., Audrey DiMauro, Ashley Pistorio, Stewart Hendry, and Xiaoqin Wang. "Vocalization induced cFos expression in marmoset cortex." Front Integr Neurosci 4, no. 128 (2010): 115-121.
                                    <a href="http://quote.ucsd.edu/millerlab/files/2012/11/2010_MillerEtAl_b.pdf">[web]</a>
                                        <a href="publications/2010_Miller_FrontIntgrNeurosci_cFos.pdf"> [pdf]</a>
                                    </li>
                                    
                                    <li type="square">Miller, Cory T., Katherine Mandel, and Xiaoqin Wang. "The communicative content of the common marmoset phee call during antiphonal calling."American journal of primatology 72, no. 11 (2010): 974-980.
                                    <a href="http://onlinelibrary.wiley.com/doi/10.1002/ajp.20854/full">[web]</a>
                                        <a href="publications/2010_AmJPrimatol_MillerEtAl_phee.pdf"> [pdf]</a>
                                    </li>
                                    
                                    <li type="square">Miller, Cory T., Steven J. Eliades, and Xiaoqin Wang. "Motor planning for vocal production in common marmosets." Animal Behaviour 78, no. 5 (2009): 1195-1203.
                                    <a href="http://www.sciencedirect.com/science/article/pii/S0003347209003893">[web]</a>
                                        <a href="publications/2009_AnimalBehav_Miller_motor.pdf"> [pdf]</a>
                                    </li>
                                    
                                    <li type="square">Miller, Cory T., Kaylin Beck, Brooke Meade, and Xiaoqin Wang. "Antiphonal call timing in marmosets is behaviorally significant: interactive playback experiments." Journal of Comparative Physiology A 195, no. 8 (2009): 783-789.
                                    <a href="http://link.springer.com/article/10.1007/s00359-009-0456-1">[web]</a>
                                        <a href="publications/2009_JCompNeurobioA_Miller.pdf"> [pdf]</a>
                                    </li>
                                    <li type="square">Eliades, Steven J., and Xiaoqin Wang. "Neural substrates of vocalization feedback monitoring in primate auditory cortex." Nature 453, no. 7198 (2008): 1102-1106.
                                    <a href="http://www.nature.com/nature/journal/v453/n7198/abs/nature06910.html">[web]</a>
                                        <a href="publications/2008_Nature_Eliades_feedback.pdf"> [pdf]</a>
                                    </li>
                                    
                                    <li type="square">Pistorio, Ashley L., Brett Vintch, and Xiaoqin Wang. "Acoustic analysis of vocal development in a New World primate, the common marmoset (Callithrix jacchus) a)." The Journal of the Acoustical Society of America 120, no. 3 (2006): 1655-1670.
                                    <a href="http://scitation.aip.org/content/asa/journal/jasa/120/3/10.1121/1.2225899">[web]</a>
                                        <a href="publications/2006_JASA_Pistorio.pdf"> [pdf]</a>
                                    </li>
                                    <li type="square">DiMattina, Christopher, and Xiaoqin Wang. "Virtual vocalization stimuli for investigating neural representations of species-specific vocalizations."Journal of neurophysiology 95, no. 2 (2006): 1244-1262.
                                    <a href="http://jn.physiology.org/content/95/2/1244.short">[web]</a>
                                        <a href="publications/2006_JNeurophysiol_DiMattina.pdf"> [pdf]</a>
                                    </li>
                                    
                                    <li type="square">Miller, Cory T., and Xiaoqin Wang. "Sensory-motor interactions modulate a primate vocal behavior: antiphonal calling in common marmosets." Journal of comparative physiology A 192, no. 1 (2006): 27-38.
                                    <a href="http://link.springer.com/article/10.1007/s00359-005-0043-z">[web]</a>
                                        <a href="publications/2006_JCompBio_Miller.pdf"> [pdf]</a>
                                    </li>
                                    <li type="square">Eliades, Steven J., and Xiaoqin Wang. "Dynamics of auditory–vocal interaction in monkey auditory cortex." Cerebral Cortex 15, no. 10 (2005): 1510-1523.
                                    <a href="http://cercor.oxfordjournals.org/content/15/10/1510.short">[web]</a>
                                        <a href="publications/2005_CerebCtx_Eliades.pdf"> [pdf]</a>
                                    </li>
                                    <li type="square">Eliades, Steven J., and Xiaoqin Wang. "Sensory-motor interaction in the primate auditory cortex during self-initiated vocalizations." Journal of neurophysiology 89, no. 4 (2003): 2194-2207.
                                    <a href="http://jn.physiology.org/content/89/4/2194.short">[web]</a>
                                        <a href="publications/2003_JNeurophysiol_Eliades.pdf"> [pdf]</a>
                                    </li>
                                    <li type="square">Wang, Xiaoqin. "On cortical coding of vocal communication sounds in primates." Proceedings of the National Academy of Sciences 97, no. 22 (2000): 11843-11849.
                                    <a href="http://www.pnas.org/content/97/22/11843.full">[web]</a>
                                        <a href="publications/2000_PNAS_Wang.pdf"> [pdf]</a>
                                    </li>
                                    
                                </ul>
                                <footer>
                                    <a href="publication.html" class="button">Full publication list</a>
                                </footer>
								</section>
								<hr />
                                
<!-- shared side bar starts here -->
								<section>
									<header>
										<h3><a href="#">Wang Lab Research Projects</a></h3>
									</header>
									<div class="row 50%">
										<div class="4u">
											<a href="2coding.html" class="image fit"><img src="images/logo/research-1coding-1.jpg" alt="" /></a>
										</div>
										<div class="8u">
											<h4><a href="2coding.html">Neural Coding in Auditory Cortex</a></h4>
										</div>
									</div>
									<div class="row 50%">
										<div class="4u">
											<a href="3vocalization.html" class="image fit"><img src="images/logo/research-2vocal-1.jpg" alt="" /></a>
										</div>
										<div class="8u">
											<h4><a href="3vocalization.html">Vocalization</a></h4>
										</div>
									</div>
									<div class="row 50%">
										<div class="4u">
											<a href="4pitch.html" class="image fit"><img src="images/logo/research-3pitch-1.jpg" alt="" /></a>
										</div>
										<div class="8u">
											<h4><a href="4pitch.html">Pitch and Harmonics</a></h4>
										</div>
									</div>
									<div class="row 50%">
										<div class="4u">
											<a href="5localization.html" class="image fit"><img src="images//logo/research-5localization-1.jpg" alt="" /></a>
										</div>
										<div class="8u">
											<h4><a href="5localization.html">Sound Localization</a></h4>
										</div>
									</div>
                                    <div class="row 50%">
										<div class="4u">
											<a href="6ci.html" class="image fit"><img src="images/logo/research-6ci-1.jpg" alt="" /></a>
										</div>
										<div class="8u">
											<h4><a href="6ci.html">Cochlear Implant</a></h4>
										</div>
									</div>
                                    <div class="row 50%">
										<div class="4u">
											<a href="7behav.html" class="image fit"><img src="images/logo/research-7behav-1.jpg" alt="" /></a>
										</div>
										<div class="8u">
											<h4><a href="7behav.html">Behavior and Psychophysics</a></h4>
										</div>
									</div>

								</section>
<!-- shared side bar ends here -->
							</div>
                            
						</div>
						<hr />
					</div>

				</div>

			<!-- Footer -->
				<div id="footer">
					<div class="container">
<!-- shared section start here  -->
						<div class="row">
							<div class="12u">
								<!-- Contact -->
									<section class="contact">
										<header>
											<h3>Contact Info</h3>
										</header>
										<p> 
                                            Department of Biomedical Engineering at Johns Hopkins University <br> 
                                            720 Rutland Ave. Traylor 410. Baltimore, MD 21205, USA<br>
                                            Lab Tel: 410.502.6019&nbsp;&nbsp; |&nbsp;&nbsp;Dr. Wang Tel: 410.614.4547&nbsp;&nbsp; |&nbsp;&nbsp;Fax: 410.502.2826 <br>
                                            
                                        </p>
									</section>
								<!-- Copyright -->
									<div class="copyright">
										<ul class="menu">
                                            <li>&copy; Wang Lab at Johns Hopkins University.</li><li>Webmaster: Yueqi Guo <a href="mailto:yguo29@jhu.edu">(contact me)</a></li>
										</ul>
									</div>
							</div>
						</div>
<!-- shared section stop here  -->  
                    </div>
				</div>

		</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.dropotron.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/jquery.onvisible.min.js"></script>
			<script src="assets/js/skel.min.js"></script>
			<script src="assets/js/util.js"></script>
			<!--[if lte IE 8]><script src="assets/js/ie/respond.min.js"></script><![endif]-->
			<script src="assets/js/main.js"></script>

	</body>
</html>