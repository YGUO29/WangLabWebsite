<!DOCTYPE HTML>
<!--
	Helios by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Wang Lab - research</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<!--[if lte IE 8]><script src="assets/js/ie/html5shiv.js"></script><![endif]-->
		<link rel="stylesheet" href="assets/css/main.css" />
		<!--[if lte IE 8]><link rel="stylesheet" href="assets/css/ie8.css" /><![endif]-->
        <base target="_blank">
	</head>
	<body class="right-sidebar">
		<div id="page-wrapper">

			<!-- Header -->
				<div id="header">
					<!-- Inner -->
						<div class="inner">
							<header>
								<h1><a href="index.html" id="logo"> Research Highlights - Behavior and Psychophysics</a></h1>
							</header>
						</div>

<!-- shared navigation starts here -->                    
                    <nav id="nav">
                    <ul>
                    <li><a href="index.html" target="_self">Home</a></li>

                    <!--research headlin-->
                    <li>
                        <a href="#">Research</a>
                        <ul>

                            <li><a href="1review.html" target="_self"> Review Articles </a></li>
                            <li><a href="2coding.html" target="_self"> Neural Coding </a></li>
                            <li><a href="3vocalization.html" target="_self"> Vocalization </a></li>
                            <li><a href="4pitch.html" target="_self"> Pitch and Harmonics </a></li>
                            <li><a href="5localization.html" target="_self"> Sound Localization </a></li>
                            <li><a href="6ci.html" target="_self"> Cochlear Implant</a></li>
                            <li><a href="7behav.html" target="_self"> Behavior and Psychophysics </a></li>
                            <li><a href="8method.html" target="_self"> Methods </a></li>
                        </ul>
                    </li>

                    <!--people headline (left-sidebar)-->
                    <li><a href="people.html" target="_self">People</a></li>
                    <!--publication headline (right-sidebar-->
                    <li><a href="publication.html" target="_self"> Publications </a></li>
                    <!--photos headline (no sidebar)-->
                    <li><a href="adventure.html" target="_self">Adventures</a></li>
                    <li><a href="positions.html" target="_self">Positions</a></li>
                    </ul>
                    </nav>
<!-- shared navigation ends here -->    
				</div>

			<!-- Main -->
				<div class="wrapper style1">
					<div class="container">
						<div class="row 200%">
							
                            <div class="8u 12u(mobile)" id="content" >
								<article id="main" >
                                <section><h3><i>We trained marmosets with an operant conditioning behavioral paradigm on auditory tasks (tone detection, discrimination of vocalizations and pitch etc.) to study their basic auditory perception capacities and vocal behaviors. We also conduct human psychophysical experiments related to music perception and auditory-tactile integration. </i></h3></section>
<!-- 2016, FDL -->
                                <section>
                                <h3><a href="http://www.sciencedirect.com/science/article/pii/S0378595516301733?np=y">Frequency discrimination in the common marmoset (Callithrix jacchus)</a></h3>
                                </section>
                                <section>
                                <a href="http://www.sciencedirect.com/science?_ob=MiamiCaptionURL&_method=retrieve&_eid=1-s2.0-S0378595516301733&_image=1-s2.0-S0378595516301733-gr4.jpg&_cid=271141&_explode=defaultEXP_LIST&_idxType=defaultREF_WORK_INDEX_TYPE&_alpha=defaultALPHA&_ba=&_rdoc=1&_fmt=FULL&_issn=03785955&_pii=S0378595516301733&md5=04b3857b2d5773c3e6b0a2a3f0538e49" class="image research-right"><img src="images/research/7-3.jpg" alt="" /></a>
                                <p><b>(Osmanski et al., 2016) </b>Highlights: 1) Frequency difference limens (FDLs) were measured in common marmosets across most of their hearing range; 2) Marmosets' FDLs are comparable to other New World primates, with lowest values in the frequency range of ∼3.5–14 kHz; 3) Lowest FDLs correspond with marmosets' lowest hearing thresholds and the spectral energy contained in their vocalizations.</p>    
                                <p style="font-size: 14px">
                                Figure 4. Comparison of FDLs obtained from the current study (“Marmoset, 2016”, solid red line) with FDLs of other primate species measured by previous studies (squirrel monkey (Wienicke et al., 2001 and Capps and Ades, 1968), owl monkey (Recanzone et al., 1991), Old World monkeys (Prosen et al., 1990), Cercopithecinae (Sinnott et al., 1992, Sinnott et al., 1987, Sinnott et al., 1985 and Stebbins, 1973), Chimpanzee (Kojima, 1990), and human (Sinnott et al., 1992, Sinnott et al., 1987, Sinnott et al., 1985 and Wier et al., 1977)). In general, humans show the lowest FDLs, followed by non-human apes and Old World monkeys. New World monkeys show the largest FDLs compared to other primates.
                                </p>
                                </section>
                                    
                                    
<!--2012, Tactile -->
                                <section>
                                <h3><a href="http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0048496">Feeling Music: Integration of Auditory and Tactile Inputs in Musical Meter Perception</a></h3>
                                </section>
                                <section>
                                <a href="http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0048496" class="image research-left"><img src="images/research/7-1.png" alt="" /></a>
                                <p><b>(Huang et al., 2012) </b>Musicians often say that they not only hear, but also “feel” music. To explore the contribution of tactile information in “feeling” musical rhythm, we investigated the degree that auditory and tactile inputs are integrated in humans performing a musical meter recognition task. Subjects discriminated between two types of sequences, ‘duple’ (march-like rhythms) and ‘triple’ (waltz-like rhythms) presented in three conditions: 1) Unimodal inputs (auditory or tactile alone), 2) Various combinations of bimodal inputs, where sequences were distributed between the auditory and tactile channels such that a single channel did not produce coherent meter percepts, and 3) Simultaneously presented bimodal inputs where the two channels contained congruent or incongruent meter cues. We first show that meter is perceived similarly well (70%–85%) when tactile or auditory cues are presented alone. We next show in the bimodal experiments that auditory and tactile cues are integrated to produce coherent meter percepts. Performance is high (70%–90%) when all of the metrically important notes are assigned to one channel and is reduced to 60% when half of these notes are assigned to one channel. When the important notes are presented simultaneously to both channels, congruent cues enhance meter recognition (90%). Performance drops dramatically when subjects were presented with incongruent auditory cues (10%), as opposed to incongruent tactile cues (60%), demonstrating that auditory input dominates meter perception. We believe that these results are the first demonstration of cross-modal sensory grouping between any two senses.</p>    
                                <p style="font-size: 14px">
                                Figure 3. Each open bar represents a 500 ms silence. Each dark bar represents a note (pure tone/sinusoidal vibration) with a duration of 350 ms followed by 150 ms of silence. Larger dark in accented trials represent an amplitude accent, with 20 dB higher amplitude than regular dark notes. Exp. 1: unimodal trial, a whole triple sequence is assigned to either auditory or tactile modality. Ex. 2 and 3: bimodal trials, dark bars in channel 1 and channel 2 together compose a whole triple sequence. Exp. 4: bimodal trials, channel 1 contain a whole triple sequence, channel 2 contain additional Triple (Congruent) or Duple (Incongruent) M notes. For Exp. 2, 3, and 4, channel 1 notes sent to one modality and channel 2 notes sent to another modality. Channel 1 and 2 notes are assigned to either auditory and tactile modalities, or tactile and auditory modalities, respectively.  
                                </p>
                                </section>
                            
<!--2011, audiogram -->
                            <section>
                            <h3><a href="http://www.sciencedirect.com/science/article/pii/S0378595511000232">Measurement of absolute auditory thresholds in the common marmoset</a></h3>
                            </section>
                            <section>
                                    <a href="http://www.sciencedirect.com/science?_ob=MiamiCaptionURL&_method=retrieve&_eid=1-s2.0-S0378595511000232&_image=1-s2.0-S0378595511000232-gr3.jpg&_cid=271141&_explode=defaultEXP_LIST&_idxType=defaultREF_WORK_INDEX_TYPE&_alpha=defaultALPHA&_ba=&_rdoc=1&_fmt=FULL&_issn=03785955&_pii=S0378595511000232&md5=74ee065dc29b1d686a0c360e671b3897" class="image research-right"><img src="images/research/7-2.jpg" alt="" /></a>
                                    <p><b>(Osmanski et al., 2011) </b>The present experiment pairs psychophysics with an operant conditioning technique to examine perception of pure tone stimuli by marmosets using an active behavioral paradigm. Subjects were trained to lick at a feeding tube when they detected a sound. Correct responses provided access to a food reward. Pure tones of varying intensities were presented to subjects using the method of constant stimuli. Behavioral thresholds were calculated for each animal based on hit rate – threshold was defined by the tone intensity that the animal correctly identified 50% of the time. Results show that marmoset hearing is comparable to that of other New World monkeys, with a hearing range extending from about 125 Hz up to 36 kHz and a sensitivity peak around 7 kHz.</p>
                                    <p style="font-size: 14px">
                                    Figure 3. Comparison of audiograms obtained from the current study (bold solid line, shaded area denotes one standard deviation from the mean) and several previous studies (common marmosets (Seiden, 1957), squirrel monkeys (Beecher, 1974b), owl monkeys (Beecher, 1974a), and humans (Jackson et al., 1999)).
                            
									</p>
                                    </section>
  
                                </article>
                            </div>

							<div class="4u 12u(mobile)" id="sidebar">
                            <hr class="first" />
                            <section>
<!--  related publication -->                             
                            <header>
                            <h3>Related publications</h3>
                            </header>
                                <ul>
                                    <li type="square">Osmanski, Michael S., Xindong Song, Yueqi Guo, and Xiaoqin Wang. "Frequency discrimination in the common marmoset (Callithrix jacchus)" Hearing Research (2016).
                                    <a href="http://www.sciencedirect.com/science/article/pii/S0378595516301733">[web]</a>
                                        <a href="publications/2016_HearingRes_Osmanski.pdf"> [pdf]</a>
                                    </li>
                                    
                                    <li type="square">Song, Xindong, Michael S. Osmanski, Yueqi Guo, and Xiaoqin Wang. "Complex pitch perception mechanisms are shared by humans and a New World monkey." Proceedings of the National Academy of Sciences 113, no. 3 (2016): 781-786.
                                    <a href="http://www.pnas.org/content/113/3/781.short">[web]</a>
                                        <a href="publications/2016_PNAS_Song_PitchBehavior.pdf"> [pdf]</a>
                                    </li>
                                    <li type="square">Osmanski, Michael S., Xindong Song, and Xiaoqin Wang. "The role of harmonic resolvability in pitch perception in a vocal nonhuman primate, the common marmoset (Callithrix jacchus)." The Journal of Neuroscience 33, no. 21 (2013): 9161-9168.
                                    <a href="http://www.jneurosci.org/content/33/21/9161.short">[web]</a>
                                        <a href="publications/2013_JNeurosci_Osmanski_resolvability.pdf"> [pdf]</a>
                                    </li>
                                    <li type="square">Osmanski, Michael S., and Xiaoqin Wang. "Measurement of absolute auditory thresholds in the common marmoset (Callithrix jacchus)." Hearing research 277, no. 1 (2011): 127-133.
                                    <a href="http://www.sciencedirect.com/science/article/pii/S0378595511000232">[web]</a>
                                        <a href="publications/2011_HearRes_Osmanski.pdf"> [pdf]</a>
                                    </li>
                                    <li type="square">Huang, Juan, Darik Gamble, Kristine Sarnlertsophon, Xiaoqin Wang, and Steven Hsiao. "Feeling music: integration of auditory and tactile inputs in musical meter perception." PloS one 7, no. 10 (2012): e48496.
                                    <a href="http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0048496">[web]</a>
                                        <a href="publications/2012_PLoSONE_Huang_tactile.pdf"> [pdf]</a>
                                    </li>

                                </ul>
                                <footer>
                                    <a href="publication.html" class="button">Full publication list</a>
                                </footer>
								</section>
								<hr />
                                
<!-- shared side bar starts here -->
								<section>
									<header>
										<h3><a href="#">Wang Lab Research Projects</a></h3>
									</header>
									<div class="row 50%">
										<div class="4u">
											<a href="2coding.html" class="image fit"><img src="images/logo/research-1coding-1.jpg" alt="" /></a>
										</div>
										<div class="8u">
											<h4><a href="2coding.html">Neural Coding in Auditory Cortex</a></h4>
										</div>
									</div>
									<div class="row 50%">
										<div class="4u">
											<a href="3vocalization.html" class="image fit"><img src="images/logo/research-2vocal-1.jpg" alt="" /></a>
										</div>
										<div class="8u">
											<h4><a href="3vocalization.html">Vocalization</a></h4>
										</div>
									</div>
									<div class="row 50%">
										<div class="4u">
											<a href="4pitch.html" class="image fit"><img src="images/logo/research-3pitch-1.jpg" alt="" /></a>
										</div>
										<div class="8u">
											<h4><a href="4pitch.html">Pitch and Harmonics</a></h4>
										</div>
									</div>
									<div class="row 50%">
										<div class="4u">
											<a href="5localization.html" class="image fit"><img src="images//logo/research-5localization-1.jpg" alt="" /></a>
										</div>
										<div class="8u">
											<h4><a href="5localization.html">Sound Localization</a></h4>
										</div>
									</div>
                                    <div class="row 50%">
										<div class="4u">
											<a href="6ci.html" class="image fit"><img src="images/logo/research-6ci-1.jpg" alt="" /></a>
										</div>
										<div class="8u">
											<h4><a href="6ci.html">Cochlear Implant</a></h4>
										</div>
									</div>
                                    <div class="row 50%">
										<div class="4u">
											<a href="7behav.html" class="image fit"><img src="images/logo/research-7behav-1.jpg" alt="" /></a>
										</div>
										<div class="8u">
											<h4><a href="7behav.html">Behavior and Psychophysics</a></h4>
										</div>
									</div>

								</section>
<!-- shared side bar ends here -->
							</div>
                            
						</div>
						<hr />
					</div>

				</div>

			<!-- Footer -->
				<div id="footer">
					<div class="container">
<!-- shared section start here  -->
						<div class="row">
							<div class="12u">
								<!-- Contact -->
									<section class="contact">
										<header>
											<h3>Contact Info</h3>
										</header>
										<p> 
                                            Department of Biomedical Engineering at Johns Hopkins University <br> 
                                            720 Rutland Ave. Traylor 410. Baltimore, MD 21205, USA<br>
                                            Lab Tel: 410.502.6019&nbsp;&nbsp; |&nbsp;&nbsp;Dr. Wang Tel: 410.614.4547&nbsp;&nbsp; |&nbsp;&nbsp;Fax: 410.502.2826 <br>
                                            
                                        </p>
									</section>
								<!-- Copyright -->
									<div class="copyright">
										<ul class="menu">
                                            <li>&copy; Wang Lab at Johns Hopkins University.</li><li>Webmaster: Yueqi Guo <a href="mailto:yguo29@jhu.edu">(contact me)</a></li>
										</ul>
									</div>
							</div>
						</div>
<!-- shared section stop here  -->  
                    </div>
				</div>

		</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.dropotron.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/jquery.onvisible.min.js"></script>
			<script src="assets/js/skel.min.js"></script>
			<script src="assets/js/util.js"></script>
			<!--[if lte IE 8]><script src="assets/js/ie/respond.min.js"></script><![endif]-->
			<script src="assets/js/main.js"></script>

	</body>
</html>