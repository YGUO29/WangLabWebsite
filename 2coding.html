<!DOCTYPE HTML>
<!--
	Helios by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Wang Lab - research</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<!--[if lte IE 8]><script src="assets/js/ie/html5shiv.js"></script><![endif]-->
		<link rel="stylesheet" href="assets/css/main.css" />
		<!--[if lte IE 8]><link rel="stylesheet" href="assets/css/ie8.css" /><![endif]-->
        <base target="_blank">
	</head>
	<body class="right-sidebar">
		<div id="page-wrapper">

			<!-- Header -->
				<div id="header">
					<!-- Inner -->
						<div class="inner">
							<header>
								<h1><a href="index.html" id="logo"> Research Highlights - Neural Coding</a></h1>
							</header>
						</div>

<!-- shared navigation starts here -->                    
                    <nav id="nav">
                    <ul>
                    <li><a href="index.html" target="_self">Home</a></li>

                    <!--research headlin-->
                    <li>
                        <a href="#">Research</a>
                        <ul>

                            <li><a href="1review.html" target="_self"> Review Articles </a></li>
                            <li><a href="2coding.html" target="_self"> Neural Coding </a></li>
                            <li><a href="3vocalization.html" target="_self"> Vocalization </a></li>
                            <li><a href="4pitch.html" target="_self"> Pitch and Harmonics </a></li>
                            <li><a href="5localization.html" target="_self"> Sound Localization </a></li>
                            <li><a href="6ci.html" target="_self"> Cochlear Implant</a></li>
                            <li><a href="7behav.html" target="_self"> Behavior and Psychophysics </a></li>
                            <li><a href="8method.html" target="_self"> Methods </a></li>
                        </ul>
                    </li>

                    <!--people headline (left-sidebar)-->
                    <li><a href="people.html" target="_self">People</a></li>
                    <!--publication headline (right-sidebar-->
                    <li><a href="publication.html" target="_self"> Publications </a></li>
                    <!--photos headline (no sidebar)-->
                    <li><a href="adventure.html" target="_self">Adventures</a></li>
                    <li><a href="positions.html" target="_self">Positions</a></li>
                    </ul>
                    </nav>
<!-- shared navigation ends here -->    
				</div>

			<!-- Main -->
				<div class="wrapper style1">
					<div class="container">
						<div class="row 200%">
							
                            <div class="8u 12u(mobile)" id="content" >
								<article id="main" >

                                <section><h3><i>We use electrophysiology methods (single-unit extracellular recording, intracellular recording, and population electrode array recording) to investigate some basic mechanisms of neural coding in the auditory cortex. We found neurons with various response properties to sounds, including synchronized temporal code, non-synchronized firing-rate code, fine tuning to pure tones, sensitivity to spectral contrast, and high selectivity to complex sounds, etc.</i></h3></section>
                                
<!--2017, Feng, Harmonic -->                               
                                <section>
                                <h3><a href="http://www.pnas.org/content/114/5/E840.abstract">Harmonic template neurons in primate auditory cortex underlying complex sound processing</a></h3>
                                </section>
                                <section>
                                <a href="http://www.pnas.org/content/114/5/E840/F8.large.jpg" class="image research-left"><img src="images/research/2-10.jpg" alt="" /></a>    
                                <p><b>(Feng and Wang, 2017)</b> Harmonicity is a fundamental element of music, speech, and animal vocalizations. How the brain extracts harmonic structures embedded in complex sounds remains largely unknown. We have discovered a unique population of harmonic template neurons in the core region of auditory cortex of marmosets, a highly vocal primate species. Responses of these neurons show nonlinear facilitation to harmonic complex sounds over inharmonic sounds and selectivity for particular harmonic structures. Such neuronal selectivity may form the basis of harmonic processing by the brain and has important implications for music and speech processing.</p>
                                <p style="font-size: 14px">
                                Fig 5. Distributions of the BF and locations of HTNs in marmoset auditory cortex. (A) BF distributions of HTNs and non-HTNs in auditory cortex based on data from three marmosets. (B) Tonotopic map of one recorded hemisphere (marmoset M73v, right hemisphere). HTNs (black crosses) are distributed across a broad frequency range and intermingled with other neurons in A1 and R. The border between A1 and R is identified at the low-frequency reversal. C, caudal; L, lateral; LS, lateral sulcus; M, medial.
                                </p>
                                </section>  
                                    
                                    
<!--2016, Gao, rate coding -->                               
                                <section>
                                <h3><a href="http://www.sciencedirect.com/science/article/pii/S0896627316303506">Distinct Subthreshold Mechanisms Underlying Rate-Coding Principles in Primate Auditory Cortex</a></h3>
                                </section>
                                <section>
                                <a href="http://www.sciencedirect.com/science?_ob=MiamiCaptionURL&_method=retrieve&_eid=1-s2.0-S0896627316303506&_image=1-s2.0-S0896627316303506-gr1.jpg&_cid=272195&_explode=defaultEXP_LIST&_idxType=defaultREF_WORK_INDEX_TYPE&_alpha=defaultALPHA&_ba=&_rdoc=1&_fmt=FULL&_issn=08966273&_pii=S0896627316303506&md5=20459caea366e212300682c42f394325" class="image research-right"><img src="images/research/2-9.jpg" alt="" /></a>    
                                <p><b>(Gao et al, 2016)</b> Highlights: We developed a novel intracellular recording technique for awake primates; A1 neurons show unique spiking and subthreshold responses to time-varying sounds; Two types of rate-coding A1 neurons exhibited distinct subthreshold responses; Computational model provides mechanistic insights to diverse temporal coding schemes</p>
                                <p style="font-size: 14px">
                                Figure 1. Co-axial Guide Tube Protected Sharp Electrode Recording Method (A) Schematic diagram of guide-tube-anchored sharp electrode recording method. Left top (gray color), side view of the custom-made electrode holder. The co-axial grooves of the holder were used to hold the sharp electrode (small groove) and guide tube (large groove), respectively, and also functioned as a guide to align the two electrodes together. Two screws were used to fasten the recording electrode and guide tube. Right bottom (purple and pink colors), side view of the arrangement of the guide tube anchor. (B) Photograph of the recording electrode and guide tube assembly after they were loaded and fastened into the electrode holder. Scale bar, 1 mm. (C) Example traces from a cortical neuron held for 160 min at the beginning (top, at 25 min), middle (middle, at 65 min), and end of the recording (bottom, at 140 min). Gray shaded area indicates periods of sound stimulation (top, pure tone; middle, sAM tone; bottom, white broad-band noise). x axis label applied to all panels. (D) Top, an example of auditory response elicited by a tone. Bottom, the subthreshold response of the same trial after the spikes were removed by line interpolation method (note the different voltage scales). The dashed gray line is the baseline MP. Stimulus duration is indicated by the red bar. The area of subthreshold response is shown by the gray shaded area. (E) Histogram of the duration of intracellular recordings, binned to the nearest minute.
                                </p>
                                </section>    
 <!--2013, Issa, SWS -->                                   
                                <section>
                                <h3><a href="http://jn.physiology.org/content/109/11/2732.short">Increased neural correlations in primate auditory cortex during slow-wave sleep</a></h3>
                                </section>
                                <section>
                                <a href="http://jn.physiology.org/content/jn/109/11/2732/F1.large.jpg" class="image research-left"><img src="images/research/2-1.jpg" alt="" /></a>    
                                <p><b>(Issa and Wang, 2012)</b> We found that during slow-wave sleep (SWS), local (neuron-neuron) correlations are not reduced by acoustic stimulation remaining higher than in wakefulness and rapid eye movement sleep and remaining similar to spontaneous activity correlations. This high level of correlations during SWS complements previous work finding elevated global (local field potential-local field potential) correlations during sleep. Contrary to the prediction that slow oscillations in SWS would increase neural correlations during spontaneous activity, we found little change in neural correlations outside of periods of acoustic stimulation. Rather, these findings suggest that functional connections recruited in sound processing are modified during SWS and that slow rhythms, which in general are suppressed by sensory stimulation, are not the sole mechanism leading to elevated network correlations during sleep.</p>
                                <p style="font-size: 14px">
                                Figure1. Example units recorded simultaneously. A: 3 well-isolated single units (signal-to-noise ratio: unit 1 = 38 dB, unit 2 = 29 dB, unit 3 = 28 dB; see inset for spike waveforms taken from the end of the recording) were recorded simultaneously for an episode of sleep [slow-wave sleep (SWS) 1 and rapid eye movement sleep (REM) 1] followed by wakefulness and a 2nd episode of sleep (SWS 2 and REM 2; 94 min total). These 3 units showed 3 different patterns of modulation during sleep. Unit 1 was strongly driven by a sinusoidal amplitude-modulated (sAM) tone [carrier frequency = 8.7 kHz, modulation frequency = 128 Hz, 30-dB sound pressure level (SPL)] during wakefulness, but its response was strongly attenuated in SWS (gain = −73%) and REM (gain = −69%). On the other hand, unit 2 responded most strongly in SWS and had a weak response in wakefulness (gain in SWS = 83%; sAM tone: carrier frequency = 8.7 kHz, modulation frequency = 1 Hz, 30-dB SPL). Finally, unit 3 gave a consistent response across all states (gain in SWS = 15%, gain in REM = 18%; sAM tone: carrier frequency = 8.7 kHz, modulation frequency = 128 Hz, 30-dB SPL). Stimulus onset on each trial was at 100 ms, and stimulus offset was at 400 ms (vertical black lines). Gray boxes denote analysis window for computing firing rates (see materials and methods). 
                                </p>
                                </section>
                            
<!--2011, Bartlette, fine tuning -->
                            <section>
                            <h3><a href="http://jn.physiology.org/content/106/2/849.long">Fine frequency tuning in monkey auditory cortex and thalamus </a></h3>
                            </section>
                            <section>
                                    <a href="http://jn.physiology.org/content/jn/106/2/849/F1.large.jpg" class="image research-right"><img src="images/research/2-2.jpg" alt="" /></a>
                                    <p><b>(Bartlette et al., 2011)</b> How sharply are auditory cortex neurons tuned to sound frequency? Previous studies in animals have suggested that cortical tuning widths are quite broad, and usually 2x-3x broader than auditory nerve tuning widths. In humans, however, it has been reported that tuning of auditory cortex neurons are quite sharp (lesser than auditory nerve tuning widths), suggesting that fine frequency tuning is a special feature of auditory cortex. In this paper, we show that many neurons in marmoset auditory cortex show tuning widths that are quite narrow, suggesting that fine frequency tuning might be found in other animal species as well. Most thalamus neurons are also sharply tuned, suggesting that fine tuning might not be restricted to cortical areas.</p>
                                    <p style="font-size: 14px">
                                    Figure1. Primary auditory cortex (A1) and medial geniculate body (MGB) tuning bandwidths. A: distributions of bandwidths [at best sound level (BL)] for all A1 units (n = 275, black) and MGB units (n = 159, gray). B: cumulative distributions of A1 (black) and MGB (gray) bandwidths. Light gray dashed line indicates the typical bandwidth of auditory nerve fibers (0.2 oct.) that was used as a boundary to classify sharply tuned units from the rest of the population.
									</p>
                                    </section>

<!--2009, Sadagopan, nonlinear -->                         
                            <section>
                            <h3><a href="http://www.nature.com/nature/journal/v436/n7054/abs/nature03867.html">Nonlinear Spectrotemporal Interactions Underlying Selectivity for Complex Sounds in Auditory Cortex</a></h3>
                            <p style="font-size: 14px"></p>
                            </section>                         
                            <section>
                            <a href="http://www.jneurosci.org/content/29/36/11192/F4.large.jpg" class="image research-left"><img src="images/research/2-3.jpg" alt="" /></a>
                            <p><b>(Bendor and Wang, 2005)</b> We found that some non-tone responsive neurons exhibited nonlinear combination-sensitive responses that require precise spectral and temporal combinations of two tone pips. The nonlinear spectrotemporal maps derived from these neurons were correlated with their selectivity for complex acoustic features. These non-tone responsive and nonlinear neurons were commonly encountered at superficial cortical depths in A1. Our findings demonstrate how temporally and spectrally specific nonlinear integration of putative tone-tuned inputs might underlie a diverse range of high selectivity of A1 neurons in awake animals. We propose that describing A1 neurons with complex response properties in terms of tone-tuned input channels can conceptually unify a wide variety of observed neural selectivity to complex sounds into a lower dimensional description.</p>
                            <p style="font-size: 14px">
                            Figure 4. Nonlinear spectrotemporal interactions underlie complex feature selectivity in A1. A, Nonlinear interaction map of another example A1 neuron that showed strong nonlinear interactions around a BF of 6.5 kHz. B, However, this unit did not respond to a wide variety of commonly used stimuli. Red circles are responses to two-pip stimuli and pink circles are responses to pure tones. Each dot is driven response rate (after subtracting spontaneous rate) to an individual stimulus belonging to that particular stimulus set. Abbreviations used in addition to those defined in text are as follows: FRA, frequency response area (tones); Col., colony noise (environmental sounds from monkey colony); Voc., marmoset vocalizations, BW − BPN of varying bandwidths. C, Raster of two-pip responses corresponding to map in A showing robust spiking occurred after integration of both pips. 
                            </p>
                            </section>                                  
                            
<!--2008, Bendor, different area comparison -->                         
                            <section>
                            <h3><a href="http://jn.physiology.org/content/100/2/888?iss=2">Neural Response Properties of Primary, Rostral, and Rostrotemporal Core Fields in the Auditory Cortex of Marmoset Monkeys</a></h3>
                            <p style="font-size: 14px"></p>
                            </section>
                                    
                            <section>
                            <a href="http://jn.physiology.org/content/jn/100/2/888/F1.large.jpg" class="image research-right"><img src="images/research/2-4.jpg" alt="" /></a>
                            <p><b>(Bendor and Wang, 2008)</b> In this report we compare the response properties of neurons in the three core fields to pure tones and sinusoidally amplitude modulated tones in awake marmoset monkeys (Callithrix jacchus). The main observations are as follows. (1) All three fields are responsive to spectrally narrowband sounds and are tonotopically organized. (2) Field AI responds more strongly to pure tones than fields R and RT. (3) Field RT neurons have lower best sound levels than those of neurons in fields AI and R. In addition, rate-level functions in field RT are more commonly nonmonotonic than in fields AI and R. (4) Neurons in fields RT and R have longer minimum latencies than those of field AI neurons. (5) Fields RT and R have poorer stimulus synchronization than that of field AI to amplitude-modulated tones. (6) Between the three core fields the more rostral regions (R and RT) have narrower firing-rate–based modulation transfer functions than that of AI. This effect was seen only for the nonsynchronized neurons. Synchronized neurons showed no such trend.</p>
                            <p style="font-size: 14px">
                            Figure 1. Model of the organization of auditory cortex in marmosets. A: location of auditory cortex within a marmoset's left hemisphere. B: the organization of auditory fields within auditory cortex. The lateral sulcus is unfolded to show the portion of auditory cortex found within the lateral sulcus (adapted from Pistorio et al. 2005). LS, lateral sulcus; S2, secondary somatosensory area; PV, parietal ventral area; Ins, insula; AI, primary auditory cortex; R, rostral field; RT, rostral temporal field; STS, superior temporal sulcus; M, medial; R, rostral; C, caudal; L, lateral; V1, primary visual cortex; M1, primary motor cortex; S1, primary somatosensory cortex; MT, middle temporal area.
                            </p>
                            </section>                                  
                             
                            
<!--2007, Bendor, flutter rate coding -->                         
                            <section>
                            <h3><a href="http://www.nature.com/neuro/journal/v10/n6/abs/nn1888.html">Differential neural coding of acoustic flutter within primate auditory cortex</a></h3>
                            <p style="font-size: 14px"></p>
                            </section>
                                    
                            <section>
                            <a href="http://www.nature.com/neuro/journal/v10/n6/fig_tab/nn1888_F2.html" class="image research-left"><img src="images/research/2-5.jpg" alt="" /></a>
                            <p><b>(Bendor and Wang, 2007)</b> A sequence of acoustic events is perceived either as one continuous sound or as a stream of temporally discrete sounds (acoustic flutter), depending on the rate at which the acoustic events repeat. Acoustic flutter is perceived at repetition rates near or below the lower limit for perceiving pitch, and is akin to the discrete percepts of visual flicker and tactile flutter caused by the slow repetition of sensory stimulation. It has been shown that slowly repeating acoustic events are represented explicitly by stimulus-synchronized neuronal firing patterns in primary auditory cortex (AI). Here we show that a second neural code for acoustic flutter exists in the auditory cortex of marmoset monkeys (Callithrix jacchus), in which the firing rate of a neuron is a monotonic function of an acoustic event's repetition rate. Whereas many neurons in AI encode acoustic flutter using a dual temporal/rate representation, we find that neurons in cortical fields rostral to AI predominantly use a monotonic rate code and lack stimulus-synchronized discharges. These findings indicate that the neural representation of acoustic flutter is transformed along the caudal-to-rostral axis of auditory cortex.</p>
                            <p style="font-size: 14px">
                            Figure 2. (a) Distribution of the Spearman correlation coefficient for neurons with monotonic (filled bars) and non-monotonic (unfilled bars) response functions of repetition rate. Spearman correlation coefficients of 1 and –1 have perfect positive and negative monotonicity, respectively. Neurons with a statistically significant Spearman correlation coefficient are considered monotonic. (b) Normalized discharge rates for positive (blue) and negative (red) monotonic neurons. This figure includes data from all synchronized, mixed and unsynchronized neurons. Only data collected with stimulus set 1 (see Methods) are shown.
                            </p>
                            </section>    
<!--2003, Barbour, contrast tuning -->                         
                            <section>
                            <h3><a href="http://science.sciencemag.org/content/299/5609/1073">Contrast Tuning in Auditory Cortex</a></h3>
                            <p style="font-size: 14px"></p>
                            </section>                         
                            <section>
                            <a href="https://d2ufo47lrtsv5s.cloudfront.net/content/sci/299/5609/1073/F5.large.jpg" class="image research-right"><img src="images/research/2-6.jpg" alt="" /></a>
                            <p><b>(Barbour and Wang, 2003)</b> The acoustic features useful for converting auditory information into perceived objects are poorly understood. Although auditory cortex neurons have been described as being narrowly tuned and preferentially responsive to narrowband signals, naturally occurring sounds are generally wideband with unique spectral energy profiles. Through the use of parametric wideband acoustic stimuli, we found that such neurons in awake marmoset monkeys respond vigorously to wideband sounds having complex spectral shapes, preferring stimuli of either high or low spectral contrast. Low contrast–preferring neurons cannot be studied thoroughly with narrowband stimuli and have not been previously described. These findings indicate that spectral contrast reflects an important stimulus decomposition in auditory cortex and may contribute to the recognition of acoustic objects.</p>
                            <p style="font-size: 14px">
                            Figure 5. Canonical responses to spectral contrast. This coding scheme reflects complex multifrequency signal integration that cannot be predicted from frequency tuning alone. spont, spontaneous discharge rate.
                            </p>
                            </section>      
<!--2003, Kadia, multipeak -->                         
                            <section>
                            <h3><a href="http://www.nature.com/neuro/journal/v10/n6/abs/nn1888.html">Spectral Integration in A1 of Awake Primates: Neurons With Single- and Multipeaked Tuning Characteristics</a></h3>
                            <p style="font-size: 14px"></p>
                            </section>
                                    
                            <section>
                            <a href="http://jn.physiology.org/content/jn/89/3/1603/F10.large.jpg" class="image research-left"><img src="images/research/2-7.jpg" alt="" /></a>
                            <p><b>(Kadia and Wang, 2003)</b> We investigated modulations by stimulus components placed outside of the classical receptive field in the primary auditory cortex (A1) of awake marmosets. Two classes of neurons were identified using single tone stimuli: neurons with single-peaked frequency tuning characteristics (147/185, 80%) and neurons with multipeaked frequency tuning characteristics (38/185, 20%), referred to as single- and multipeaked units, respectively. Each class of neurons was further studied using two-tone paradigms in which the frequency, intensity, and timing of the second tone were systematically varied while a unit was driven by the first tone placed at a unit's characteristic frequency (CF) if it was single-peaked or at one of multiple spectral peaks if it was multipeaked. The main findings were: 1) excitatory spectral peaks in the frequency tuning of the multipeaked units were often harmonically related. 2) Multipeaked units showed facilitation in their responses to combinations of two harmonically related tones placed at the spectral peaks of their frequency tuning. The two-tone facilitation was strongest for the simultaneously presented tones. 3) In 76 of 113 single-peaked units studied using the two-tone paradigm, facilitatory and/or inhibitory modulations by distant off-CF tones were observed. This distant inhibition differed from flanking (or side-band) inhibitions near CF. 4) In single-peaked units, the distant off-CF inhibitions were dominated by tones at frequencies that were harmonically related to the CF of a unit, whereas the facilitation by off-CF tones was observed for a wide range of frequencies. And 5) in both single- and multipeaked units, sound levels of two interacting tones determined whether the two tones produced excitation or inhibition. The largest facilitation was achieved by using two tones at their corresponding preferred sound levels. Together, these findings suggest that extracting or rejecting harmonically related components embedded in complex sounds may represent fundamental signal processing properties in different classes of A1 neurons.</p>
                            <p style="font-size: 14px">
                            Figure 10. Response modulations in the population of single-peaked unit.A: distribution of major facilitatory peaks (seemethods) in 51 of 113 single-peaked units.B: distribution of major inhibitory peaks in 51 of 113 single-peaked units. The units included in this plot partially overlap with the group of units included in A. Neurons in A1 have inhibitory influences from a wide range of frequencies outside the receptive fields, predominantly from harmonically related frequencies (0.5*CF, 2*CF). C: distribution of all modulatory peaks measured from 76 of 113 units that showed facilitation and/or inhibition in their 2-tone responses. There were a total of 139 measured peaks.
                            </p>
                            </section>    
<!--2001, Lu, temporal -->                         
                            <section>
                            <h3><a href="http://www.nature.com/neuro/journal/v4/n11/abs/nn737.html">Temporal and rate representations of time-varying signals in the auditory cortex of awake primates</a></h3>
                            <p style="font-size: 14px"></p>
                            </section>                         
                            <section>
                            <a href="http://www.nature.com/neuro/journal/v4/n11/fig_tab/nn737_F3.html" class="image research-right"><img src="images/research/2-8.jpg" alt="" /></a>
                            <p><b>(Lu et al., 2001)</b> Because auditory cortical neurons have limited stimulus-synchronized responses, cortical representations of more rapidly occurring but still perceivable stimuli remain unclear. Here we show that there are two largely distinct populations of neurons in the auditory cortex of awake primates: one with stimulus-synchronized discharges that, with a temporal code, explicitly represented slowly occurring sound sequences and the other with non-stimulus-synchronized discharges that, with a rate code, implicitly represented rapidly occurring events. Furthermore, neurons of both populations displayed selectivity in their discharge rates to temporal features within a short time-window. Our results suggest that the combination of temporal and rate codes in the auditory cortex provides a possible neural basis for the wide perceptual range of temporal information.</p>
                            <p style="font-size: 14px">
                            Figure 3. Population responses to click trains.(a) Characterization of two populations of neurons by synchronization and rate-response measures. The horizontal dashed line at 13.8 indicates the statistical significance level of the Rayleigh test. The vertical dashed line indicates a discharge rate ratio of 1.0 (see Methods). White circles indicate neurons classified in the synchronized population (n = 36). Crosses indicate neurons classified in the non-synchronized rate-response population (n = 50). Black circles indicate neurons with mixed responses (n = 8). (b) Distribution of synchronization boundaries. (c) Distribution of rate-response boundaries. (d) Combination of temporal and rate representations of the entire range of tested ICIs. Each curve is the cumulative sum of the histograms representing the neural population in (b) or (c), respectively. Dashed line shows the percentage of neurons with synchronization boundaries less than or equal to a given ICI. Solid line shows the percentage of neurons with rate-response boundaries greater than or equal to a given ICI. (e) Mean vector strength across the population of synchronized neurons. Vector strength at ICIs below a neuron's synchronization boundary was set to zero. (f) Mean discharge rate across the population of non-synchronized neurons. Discharge rates at ICIs above a neuron's rate-response boundary were set to zero. Vertical bars indicate standard error of the mean in (e, f).
                            </p>
                            </section>                                     
                                </article>
                            </div>

							<div class="4u 12u(mobile)" id="sidebar">
                            <hr class="first" />
                            <section>
<!--  related publication -->                             
                            <header>
                            <h3>Related publications</h3>
                            </header>
                                <ul>
                                    <li type="square">Gao, Lixia, and Xiaoqin Wang. "Subthreshold Activity Underlying the Diversity and Selectivity of the Primary Auditory Cortex Studied by Intracellular Recordings in Awake Marmosets." Cerebral Cortex (2018).
                                        <a href="https://academic.oup.com/cercor/advance-article/doi/10.1093/cercor/bhy006/4824653">[web]</a>
                                        <a href="publications/2018_CerebCortex_Gao_SubthresholdResponse.pdf"> [pdf]</a>
                                    </li>
                                    
                                    <li type="square">Feng, L. and Xiaoqin Wang. "Harmonic template neurons in primate auditory cortex underlying complex sound processing." PNAS (2017)
                                    <a href="http://www.pnas.org/content/114/5/E840.abstract">[web]</a>
                                    <a href="publications/2017_PNAS_Feng_HarmonicTemplate.pdf"> [pdf]</a>    
                                    </li>
                                    
                                    <li type="square">Gao, Lixia, Kevin Kostlan, Yunyan Wang, and Xiaoqin Wang. "Distinct Subthreshold Mechanisms Underlying Rate-Coding Principles in Primate Auditory Cortex." Neuron (2016).
                                    <a href="http://www.sciencedirect.com/science/article/pii/S0896627316303506">[web]</a>
                                        <a href="publications/2016_Neuron_Gao.pdf"> [pdf]</a>
                                    </li> 
                                    <li type="square">Issa, Elias B., and Xiaoqin Wang. "Increased neural correlations in primate auditory cortex during slow-wave sleep." Journal of neurophysiology 109, no. 11 (2013): 2732-2738.
                                    <a href="http://jn.physiology.org/content/109/11/2732.short">[web]</a>
                                        <a href="publications/2013_JNeurosci_Issa_sleep.pdf"> [pdf]</a>
                                    </li>
                                    <li type="square">Bartlett, Edward L., Srivatsun Sadagopan, and Xiaoqin Wang. "Fine frequency tuning in monkey auditory cortex and thalamus." Journal of neurophysiology 106, no. 2 (2011): 849-859.
                                    <a href="http://jn.physiology.org/content/106/2/849.short">[web]</a>
                                        <a href="publications/2011_JNeurosci_Bartlett_finetuning.pdf"> [pdf]</a>
                                    </li>
                                    <li type="square">Bartlett, Edward L., and Xiaoqin Wang. "Correlation of neural response properties with auditory thalamus subdivisions in the awake marmoset."Journal of neurophysiology 105, no. 6 (2011): 2647-2667.
                                    <a href="http://jn.physiology.org/content/105/6/2647.short">[web]</a>
                                        <a href="publications/2011_JNeurosci_Bartlett_thalamus.pdf"> [pdf]</a>
                                    </li>
                                    <li type="square">Issa, Elias B., and Xiaoqin Wang. "Altered neural responses to sounds in primate primary auditory cortex during slow-wave sleep." The Journal of Neuroscience 31, no. 8 (2011): 2965-2973.
                                    <a href="https://www.jneurosci.org/content/31/8/2965.full">[web]</a>
                                        <a href="publications/2011_JNeurosci_Issa_slowwave.pdf"> [pdf]</a>
                                    </li>
                                    <li type="square">Zhou, Yi, and Xiaoqin Wang. "Cortical processing of dynamic sound envelope transitions." The Journal of Neuroscience 30, no. 49 (2010): 16741-16754.
                                    <a href="http://www.jneurosci.org/content/30/49/16741.short">[web]</a>
                                        <a href="publications/2010_JNeurosci_Zhou_envelopetransition.pdf"> [pdf]</a>
                                    </li>
                                    <li type="square">Sadagopan, Srivatsun, and Xiaoqin Wang. "Contribution of inhibition to stimulus selectivity in primary auditory cortex of awake primates." The Journal of Neuroscience 30, no. 21 (2010): 7314-7325.
                                    <a href="http://www.jneurosci.org/content/30/21/7314.short">[web]</a>
                                        <a href="publications/2010_JNeurosci_Sadagopan.pdf"> [pdf]</a>
                                    </li>
                                    
                                    <li type="square">Sadagopan, Srivatsun, and Xiaoqin Wang. "Nonlinear spectrotemporal interactions underlying selectivity for complex sounds in auditory cortex." The Journal of neuroscience 29, no. 36 (2009): 11192-11202.
                                    <a href="http://www.jneurosci.org/content/29/36/11192.short">[web]</a>
                                        <a href="publications/2009_JNeurosci_Sadagopan_nonlinear.pdf"> [pdf]</a>
                                        <a href="publications/2009_JNeurosci_Sadagopan_nonlinear_view.pdf"> [views]</a>
                                    </li>
                                    <li type="square">Issa, Elias B., and Xiaoqin Wang. "Sensory responses during sleep in primate primary and secondary auditory cortex." The Journal of Neuroscience 28, no. 53 (2008): 14467-14480.
                                    <a href="http://www.jneurosci.org/content/28/53/14467.short">[web]</a>
                                        <a href="publications/2008_JNeurosci_Issa.pdf"> [pdf]</a>
                                    </li>
                                    <li type="square">Bendor, Daniel, and Xiaoqin Wang. "Neural response properties of primary, rostral, and rostrotemporal core fields in the auditory cortex of marmoset monkeys." Journal of neurophysiology 100, no. 2 (2008): 888-906.
                                    <a href="http://jn.physiology.org/content/100/2/888?iss=2">[web]</a>
                                        <a href="publications/2008_JNeurophysiol_Bendor.pdf"> [pdf]</a>
                                    </li>
                                    <li type="square">Sadagopan, Srivatsun, and Xiaoqin Wang. "Level invariant representation of sounds by populations of neurons in primary auditory cortex." The Journal of neuroscience 28, no. 13 (2008): 3415-3426.
                                    <a href="https://www.jneurosci.org/content/28/13/3415.full">[web]</a>
                                        <a href="publications/2008_JNeurosci_Sadagopan.pdf"> [pdf]</a>
                                    </li>
                                    <li type="square">Bendor, Daniel, and Xiaoqin Wang. "Differential neural coding of acoustic flutter within primate auditory cortex." Nature neuroscience 10, no. 6 (2007): 763-771.
                                    <a href="http://www.nature.com/neuro/journal/v10/n6/abs/nn1888.html">[web]</a>
                                        <a href="publications/2007_NatNeurosci_Bendor.pdf"> [pdf]</a>
                                    </li>
                                    <li type="square">Bartlett, Edward L., and Xiaoqin Wang. "Neural representations of temporally modulated signals in the auditory thalamus of awake primates." Journal of neurophysiology 97, no. 2 (2007): 1005-1017.
                                    <a href="http://jn.physiology.org/content/97/2/1005.short">[web]</a>
                                        <a href="publications/2007_JNeurophysiol_Bartlett.pdf"> [pdf]</a>
                                    </li>
                                    
                                    <li type="square">Bartlett, Edward L., and Xiaoqin Wang. "Long-lasting modulation by stimulus context in primate auditory cortex." Journal of Neurophysiology 94, no. 1 (2005): 83-104.
                                    <a href="http://jn.physiology.org/content/94/1/83.short">[web]</a>
                                        <a href="publications/2005_JNeurophysiol_Bartlett.pdf"> [pdf]</a>
                                    </li>
                                    
                                    <li type="square">Wang, Xiaoqin, Thomas Lu, Ross K. Snider, and Li Liang. "Sustained firing in auditory cortex evoked by preferred stimuli." Nature 435, no. 7040 (2005): 341-346.
                                    <a href="http://www.nature.com/nature/journal/v435/n7040/abs/nature03565.html">[web]</a>
                                        <a href="publications/2005_Nature_Wang_sustained.pdf"> [pdf]</a>
                                        <a href="publications/2005_Nature_Wang_sustained_views.pdf"> [views]</a>
                                    </li>
                                    
                                    <li type="square">Lu, Thomas, and Xiaoqin Wang. "Information content of auditory cortical responses to time-varying acoustic stimuli." Journal of neurophysiology 91, no. 1 (2004): 301-313.
                                    <a href="http://jn.physiology.org/content/91/1/301.short">[web]</a>
                                        <a href="publications/2004_JNeurophysiol_Lu.pdf"> [pdf]</a>
                                    </li>
                                    <li type="square">Barbour, Dennis L., and Xiaoqin Wang. "Auditory cortical responses elicited in awake primates by random spectrum stimuli." The Journal of neuroscience23, no. 18 (2003): 7194-7206.
                                    <a href="http://www.jneurosci.org/content/23/18/7194.short">[web]</a>
                                        <a href="publications/2003_JNeurosci_Barbour_RSS.pdf"> [pdf]</a>
                                    </li>
                                    
                                    <li type="square">Barbour, Dennis L., and Xiaoqin Wang. "Contrast tuning in auditory cortex."Science 299, no. 5609 (2003): 1073-1075.
                                    <a href="http://science.sciencemag.org/content/299/5609/1073">[web]</a>
                                        <a href="publications/2003_Science_Barbour.pdf"> [pdf]</a>
                                        <a href="publications/2003_Science_Barbour_views.pdf"> [views]</a>
                                    </li>
                                    
                                    <li type="square">Kadia, Siddhartha C., and Xiaoqin Wang. "Spectral integration in A1 of awake primates: neurons with single-and multipeaked tuning characteristics."Journal of neurophysiology 89, no. 3 (2003): 1603-1622.
                                    <a href="http://jn.physiology.org/content/89/3/1603.short">[web]</a>
                                        <a href="publications/2003_JNeurophysiol_Kadia.pdf"> [pdf]</a>
                                    </li>
                                    
                                    <li type="square">Beitel, Ralph E., Christoph E. Schreiner, Steven W. Cheung, Xiaoqin Wang, and Michael M. Merzenich. "Reward-dependent plasticity in the primary auditory cortex of adult monkeys trained to discriminate temporally modulated signals." Proceedings of the National Academy of Sciences 100, no. 19 (2003): 11070-11075.
                                    <a href="http://www.pnas.org/content/100/19/11070.full">[web]</a>
                                        <a href="publications/2003_PNAS_Beitel_reward.pdf"> [pdf]</a>
                                    </li>
                                    <li type="square">Barbour, Dennis L., and Xiaoqin Wang. "Temporal coherence sensitivity in auditory cortex." Journal of neurophysiology 88, no. 5 (2002): 2684-2699.
                                    <a href="http://jn.physiology.org/content/88/5/2684.short">[web]</a>
                                        <a href="publications/2002_JNeurophyiol_Barbour.pdf"> [pdf]</a>
                                    </li>
                                    
                                    <li type="square">Liang, Li, Thomas Lu, and Xiaoqin Wang. "Neural representations of sinusoidal amplitude and frequency modulations in the primary auditory cortex of awake primates." Journal of Neurophysiology 87, no. 5 (2002): 2237-2261.
                                    <a href="http://jn.physiology.org/content/87/5/2237.short">[web]</a>
                                        <a href="publications/2002_JNeurophysiol_Liang.pdf"> [pdf]</a>
                                    </li>
                                    
                                    <li type="square">Lu, Thomas, Li Liang, and Xiaoqin Wang. "Temporal and rate representations of time-varying signals in the auditory cortex of awake primates." Nature neuroscience 4, no. 11 (2001): 1131-1138.
                                    <a href="http://www.nature.com/neuro/journal/v4/n11/abs/nn737.html">[web]</a>
                                        <a href="publications/2001_NatNeurosci_Lu.pdf"> [pdf]</a>
                                        <a href="publications/2001_NatNeurosci_Lu_views.pdf"> [views]</a>
                                    </li>
                                    <li type="square">Lu, Thomas, Li Liang, and Xiaoqin Wang. "Neural representations of temporally asymmetric stimuli in the auditory cortex of awake primates."Journal of neurophysiology 85, no. 6 (2001): 2364-2380.
                                    <a href="http://jn.physiology.org/content/85/6/2364.short">[web]</a>
                                        <a href="publications/2001_JNeurophysiol_Lu.pdf"> [pdf]</a>
                                    </li>
                                    
                                    <li type="square">Lu, Thomas, and Xiaoqin Wang. "Temporal discharge patterns evoked by rapid sequences of wide-and narrowband clicks in the primary auditory cortex of cat." Journal of neurophysiology 84, no. 1 (2000): 236-246.
                                    <a href="http://jn.physiology.org/content/84/1/236.short">[web]</a>
                                        <a href="publications/2000_JNeurophysiol_Lu.pdf"> [pdf]</a>
                                    </li>
                                    
                                    <li type="square">Wang, Xiaoqin. "On cortical coding of vocal communication sounds in primates." Proceedings of the National Academy of Sciences 97, no. 22 (2000): 11843-11849.
                                    <a href="http://www.pnas.org/content/97/22/11843.full">[web]</a>
                                        <a href="publications/2000_PNAS_Wang.pdf"> [pdf]</a>
                                    </li>
                                    
                                </ul>
                                <footer>
                                    <a href="publication.html" class="button">Full publication list</a>
                                </footer>
								</section>
								<hr />
                                
<!-- shared side bar starts here -->
								<section>
									<header>
										<h3><a href="#">Wang Lab Research Projects</a></h3>
									</header>
									<div class="row 50%">
										<div class="4u">
											<a href="2coding.html" class="image fit"><img src="images/logo/research-1coding-1.jpg" alt="" /></a>
										</div>
										<div class="8u">
											<h4><a href="2coding.html">Neural Coding in Auditory Cortex</a></h4>
										</div>
									</div>
									<div class="row 50%">
										<div class="4u">
											<a href="3vocalization.html" class="image fit"><img src="images/logo/research-2vocal-1.jpg" alt="" /></a>
										</div>
										<div class="8u">
											<h4><a href="3vocalization.html">Vocalization</a></h4>
										</div>
									</div>
									<div class="row 50%">
										<div class="4u">
											<a href="4pitch.html" class="image fit"><img src="images/logo/research-3pitch-1.jpg" alt="" /></a>
										</div>
										<div class="8u">
											<h4><a href="4pitch.html">Pitch and Harmonics</a></h4>
										</div>
									</div>
									<div class="row 50%">
										<div class="4u">
											<a href="5localization.html" class="image fit"><img src="images//logo/research-5localization-1.jpg" alt="" /></a>
										</div>
										<div class="8u">
											<h4><a href="5localization.html">Sound Localization</a></h4>
										</div>
									</div>
                                    <div class="row 50%">
										<div class="4u">
											<a href="6ci.html" class="image fit"><img src="images/logo/research-6ci-1.jpg" alt="" /></a>
										</div>
										<div class="8u">
											<h4><a href="6ci.html">Cochlear Implant</a></h4>
										</div>
									</div>
                                    <div class="row 50%">
										<div class="4u">
											<a href="7behav.html" class="image fit"><img src="images/logo/research-7behav-1.jpg" alt="" /></a>
										</div>
										<div class="8u">
											<h4><a href="7behav.html">Behavior and Psychophysics</a></h4>
										</div>
									</div>

								</section>
<!-- shared side bar ends here -->
							</div>
                            
						</div>
						<hr />
					</div>

				</div>

			<!-- Footer -->
				<div id="footer">
					<div class="container">
<!-- shared section start here  -->
						<div class="row">
							<div class="12u">
								<!-- Contact -->
									<section class="contact">
										<header>
											<h3>Contact Info</h3>
										</header>
										<p> 
                                            Department of Biomedical Engineering at Johns Hopkins University <br> 
                                            720 Rutland Ave. Traylor 410. Baltimore, MD 21205, USA<br>
                                            Lab Tel: 410.502.6019&nbsp;&nbsp; |&nbsp;&nbsp;Dr. Wang Tel: 410.614.4547&nbsp;&nbsp; |&nbsp;&nbsp;Fax: 410.502.2826 <br>
                                            
                                        </p>
									</section>
								<!-- Copyright -->
									<div class="copyright">
										<ul class="menu">
                                            <li>&copy; Wang Lab at Johns Hopkins University.</li><li>Webmaster: Yueqi Guo <a href="mailto:yguo29@jhu.edu">(contact me)</a></li>
										</ul>
									</div>
							</div>
						</div>
<!-- shared section stop here  -->  
                    </div>
				</div>

		</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.dropotron.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/jquery.onvisible.min.js"></script>
			<script src="assets/js/skel.min.js"></script>
			<script src="assets/js/util.js"></script>
			<!--[if lte IE 8]><script src="assets/js/ie/respond.min.js"></script><![endif]-->
			<script src="assets/js/main.js"></script>

	</body>
</html>